# Task Bruin - Data Pipeline project


## ğŸ³ Docker Services

### MongoDB
- **Port**: 27017
- **Database**: testDB
- **Collections**: users, orders
- **Data**: Sample test data included

## ğŸ“Š Pipeline Assets

### Data Ingestion
- **Google Sheets**: Employee salary data
- **MongoDB**: User and order data  
- **MySQL**: User profiles and orders

### Analytics Transformations
- **Employee Salary Insights**: Salary analysis and percentiles
- **User Order Analysis**: Customer segmentation and behavior
- **Cross-Platform Joins**: Unified user profiles
- **Employee-User Matching**: Cross-platform analysis


## ğŸ“ˆ Data Flow

1. **Ingestion**: Data loaded from sources to DuckDB
2. **Transformation**: SQL queries create analytics tables
3. **Materialization**: Results stored as tables for querying
4. **Quality Checks**: Data validation and integrity checks
